以下内容将旧项目中**所有可复用的产品信息、链路、技术决策与复盘结论**集中迁移到此文件，作为新项目的“唯一原始需求文档”。已按产品经理视角结构化，便于你直接作为新项目启动与复盘依据使用。

---

# 一、产品定位与愿景（已确认）
## 1.1 核心使命
帮助驾考与各类突击考试的自学者，将**杂乱题库**迅速转换成**可持续刷题的高质量网页体验**，并记录解析与学习历程。  
（来源：`docs/design/Prd.md`）

## 1.2 目标人群（Persona）
- **自主备考学员**：希望快速导入真题/模拟题，在手机或电脑上一键刷题。
- **驾校/培训班突击学员**：备考时间有限，关注题目覆盖率与错题复盘。
- **核心痛点**：题库格式混乱、转换耗时、缺乏实时刷题界面与解析状态反馈。

## 1.3 价值主张（用户得到什么）
1. 将“题库文件 → 刷题网页”的链路缩短到一次上传。
2. 题库解析过程可视化（状态、进度、错误原因）。
3. 题库沉淀可复用（历史题库列表、可重新生成）。

---

# 二、产品链路（MVP 级闭环）
## 2.1 核心链路（必须保留）
**注册/登录 → 上传题库 → 解析队列 → 生成 HTML → 题库列表 → 单页刷题**

## 2.2 用户操作流程（最小闭环）
1. 用户注册/登录（JWT 会话）。
2. 上传题库文件（MVP 仅 TXT/MD）。
3. 后端解析入队（BullMQ）。
4. Worker 解析并生成 HTML（AI 或 mock）。
5. 前端轮询 job 状态，渲染刷题页面。
6. 题库在“历史列表”中可查看、可复用。

---

# 三、MVP 功能清单（已落地共识）
1. 邮箱注册/登录与 JWT 会话。
2. 题库上传（仅 TXT/MD，含大小校验）。
3. BullMQ 队列 + Worker 解析。
4. 解析进度与失败提示。
5. 题库管理列表（状态、题量、时间）。
6. 单页刷题（iframe 嵌入 HTML）。
7. Supabase/Postgres 存储用户、题库、任务与日志。

---

# 四、V2 及以后（非当前开发范围）
- 错题本与学习统计、进度跟踪。
- 更多刷题模式（随机/章节/错题重练）。
- n8n 等自动化集成（通知/批量导入）。
- OCR、图像解析、多语言支持。
- 团队共享、协作题库。
- 邮箱验证/密码重置/第三方登录。

---

# 五、关键业务规则（Business Rules）
1. 每次上传创建一条 `quiz` 记录（`pending → processing → completed/failed`）。
2. Worker 解析失败即停止任务、写入 `job.error` 并标记 `quiz.status=failed`。
3. 只允许登录用户上传/刷题。
4. 解析生成的 HTML 不允许手动编辑。
5. 历史题库保留，允许失败后重新上传。

---

# 六、数据契约（可直接复用）
- `users(id, email, password_hash, name, is_active, created_at)`
- `quizzes(id, user_id, title, description, order_mode, status, html, file_path, error_msg, created_at, updated_at)`
- `jobs(id, quiz_id, user_id, type, status, progress, data, result, error, created_at, updated_at)`
- `parse_logs(raw_text_length, question_count, warnings, detected_format, created_at)`

---

# 七、架构蓝图（可复用技术逻辑）
## 7.1 核心流程（概念链路）
用户上传 → 存储文件 → 创建 quiz + job → 入队 → Worker 解析 → 生成 HTML → 更新状态 → 前端展示

## 7.2 推荐组件（从旧文档中抽取）
- **前端**：Next.js（现有 UI 已完成），上传与列表状态流已具备。
- **后端**：Express/Fastify + TypeScript（最终建议统一一套）。
- **队列**：BullMQ + Redis（异步解析）。
- **数据库**：Prisma + Postgres（Supabase / Neon）。
- **存储**：MVP 用本地 `uploads/`，后续可换对象存储。
- **AI**：Gemini API（缺 key 可 mock）。

---

# 八、失败项目复盘（必须固化的经验）
## 8.1 失败根因（来自 2026-01-17 评估）
1. **架构多套并存**：Strapi → Express → Next.js Serverless，导致方向漂移。
2. **数据库配置冲突**：SQLite/Postgres/Mongo 并存，导致实际无法启动。
3. **环境变量缺失**：前端无法连接后端；线上配置不完整。
4. **前后端通信失败**：端口与路由不一致，`/api/health` 缺失。

## 8.2 产品层面问题
- 需求文档与代码偏离，导致“做出来却无法运行”。
- MVP 必须“功能可用”而非“功能齐全”。
- 缺少单一技术路线与可持续部署方案。

## 8.3 迁移铁律（新项目必须遵守）
1. **只允许一套架构**，所有文档与代码保持一致。
2. **数据契约先行**，任何功能扩展必须先更新数据模型。
3. **可运行优先**：任何新增必须保证本地可运行与可演示。
4. **环境变量作为交付物**，缺一不可（API URL、DB、AI Key）。

---

# 九、新项目迁移原则（执行标准）
## 9.1 技术路线（必须择一）
**方案 A：Next.js 一体化（推荐）**  
前端 + API Routes 统一部署（Vercel），后端逻辑迁入 `study-app/app/api/`。

**方案 B：前后端分离**  
前端 Next.js + 后端 Express/Fastify（Render/自建），更独立但部署复杂。

## 9.2 可迁移资产清单（已验证）
- 题库解析流程设计（解析 → 结构化 → HTML 生成）。
- BullMQ 任务体系（job 状态流转）。
- 题库列表 UI 与上传交互（前端已完成）。
- 业务规则（上传即建 quiz、失败即标记）。
- 数据契约（users/quizzes/jobs/parse_logs）。

---

# 十、学校内部打穿路径（增长策略草案）
## 10.1 切入点
**场景：驾校/培训班/课程讲师**  
痛点：现有题库杂乱，转换耗时，学员无法持续刷题。

## 10.2 打穿策略（从内而外）
1. 与一个小班级/社团合作试点，提供“专属题库页面”。
2. 通过老师/助教推动“每周刷题任务”，形成稳定使用频率。
3. 推出“题库导入模板 + 解析失败修复服务”，降低老师成本。
4. 在校内群/课程群里建立“题库更新公告”，形成传播闭环。

## 10.3 核心指标
- 题库上传成功率
- 题库生成平均耗时
- 题库被刷题的转化率（上传后实际刷题）
- 周活用户数（WAU）

---

# 十一、数据资产沉淀（下次开发可直接使用）
## 11.1 核心实体资产
- 用户 `users`
- 题库 `quizzes`
- 任务 `jobs`
- 解析日志 `parse_logs`

## 11.2 内容资产
- 解析后的 HTML 题库（可复用）
- 原始题库文件（TXT/MD）

## 11.3 运营与分析资产
- 上传成功率、解析失败率
- 平均解析耗时
- 题库生成后的刷题转化

## 11.4 代码资产（建议迁移）
- 解析逻辑与结构化规则（parser）
- HTML 生成模板（generateQuizHTML）
- Job 状态流转逻辑

---

# 十二、新项目启动检查清单（交付标准）
1. **路线唯一**：技术栈仅保留一套。
2. **本地可运行**：前后端可联调、上传可用。
3. **部署可复现**：Vercel/Render/Neon 环境变量齐全。
4. **MVP 最小闭环**：上传→解析→刷题完整通。
5. **文档与代码一致**：一旦变更必须同步本文件。

---

# 待确认（下一轮决策必须完成）
1. 新项目选择方案 A 还是方案 B？
2. 数据库最终使用 Supabase 还是 Neon？
3. AI 解析是否继续 Gemini？是否支持“无 Key 的 mock 模式”？
4. 题库格式是否仍只支持 TXT/MD（MVP）？
5. 上线优先指标是“可用性”还是“覆盖率”？

---

本文件即为迁移原始文档：  
**新项目的一切需求、开发与复盘必须以此为准。**
